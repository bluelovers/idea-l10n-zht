action.add.job.title=提交作业
action.cancel.job.confirm.msg=是否取消“{0}”作业?
action.cancel.job.title=取消作业
action.clone.job.title=克隆作业
action.cluster.remove.confirm.msg=是否删除集群“{0}”?
action.cluster.start.confirm.msg=是否启动集群“{0}”?
action.cluster.terminate.confirm.msg=是否终止集群“{0}”?
action.confirm.title=确认
action.delete.job.confirm.msg=是否删除“{0}”作业?
action.delete.job.title=删除作业
action.open.stage.bucket=打开暂存存储桶
action.sftp=打开到节点的 SFTP
action.sftp.master.node=打开到主节点的 SFTP
action.ssh=打开到节点的 SSH
action.ssh.master.node=通过 SSH 连接到主节点
add.job.title=提交作业
add.new.submit.connection.label=添加 Dataproc 连接…
cell.execution.finished.msg=作业“{0}”已完成，状态为 {1}。
cell.execution.finished.title=Dataproc 作业
cluster.action.delete=删除集群
cluster.action.start=启动集群
cluster.action.stop=终止集群
cluster.info.config.autoscaling=自动扩缩\:
cluster.info.config.master.node.desc=主节点\:
cluster.info.config.metastore=Dataproc 元存储\:
cluster.info.config.monitoring=完整性监控\:
cluster.info.config.network=网络\:
cluster.info.config.region=区域\:
cluster.info.config.scheduled.deletion=定时删除\:
cluster.info.config.secure.boot=安全启动\:
cluster.info.config.vtpm=VTPM\:
cluster.info.config.worker.node.desc=工作进程节点\:
cluster.info.config.zone=可用区
cluster.info.image.created=创建时间\:
cluster.info.image.version=映像版本\:
cluster.info.internal.ip=仅限内部 IP\:
cluster.info.optional.components=可选组件\:
cluster.info.summary.name=名称\:
cluster.info.summary.state=状态\:
cluster.info.summary.state.details=状态详细信息\:
cluster.info.summary.type=类型\:
cluster.info.summary.uiid=集群 UUID\:
cluster.tab.applications.title=应用程序
cluster.tab.info.title=信息
cluster.tab.jobs.title=作业
cluster.tab.name=集群
cluster.tab.vb.instances.title=VM 实例
data.clusterInfo.created=Created
data.clusterInfo.id=ID
data.clusterInfo.name=名称
data.clusterInfo.region=区域
data.clusterInfo.scheduledDeletion=定时删除
data.clusterInfo.stagingBucket=暂存存储分区
data.clusterInfo.state=状态
data.clusterInfo.totalWorkers=工作进程总数
data.clusterInfo.zone=区域
data.jobInfo.cluster=集群
data.jobInfo.elapsedTime=经过时间
data.jobInfo.id=ID
data.jobInfo.labels=标签
data.jobInfo.startTime=开始时间
data.jobInfo.status=状态
data.jobInfo.type=按类型分组
data.vm.instanceInfo.componentGateway=组件 Gateway
data.vm.instanceInfo.name=名称
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=名称
data.web.interfaceInfo.role=角色
datamanager.configuration=配置
datamanager.job.info=作业信息
datamanager.labels=标签
datamanager.properties=属性
datamanager.summary=汇总
dataproc.error=Dataproc 错误
dataproc.error.cluster.must.be.started=集群必须正在运行。
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=GC Dataproc 项目
emr.remove.linked.connections.title=Dataproc 连接
error.connection.is.not.found=未为 Dataproc 设置连接。请重新创建。
error.json.auth.limited.msg=仅当您使用 gcloud CLI 在 Dataproc 中进行身份验证时，此操作才可用
error.json.auth.limited.title=操作不可用
error.spark.is.not.found=集群不包含Spark History Server
exportable.DataprocSettings.presentable.name=Big Data Tools Dataproc 设置
exportable.DataprocSshKeyPaths.presentable.name=Big Data Tools Dataproc SSH 设置
group.name.dataproc=GC Dataproc
info.value.off=关闭
instance.config.gpu.number=GPU 数量
instance.config.local.ssd=本地 SSD
instance.config.machineType=机器类型\:
instance.config.primary.disk.size=主磁盘大小\:
instance.config.primary.disk.type=主磁盘类型\:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=客户端标记
job.info.cluster=集群\:
job.info.continue.on.failure=失败时继续
job.info.elapsed.time=经过时间\:
job.info.jobId=作业 ID\:
job.info.jobUuid=作业 UUID\:
job.info.max.restart.per.hour=每小时最大重启次数\:
job.info.max.restart.per.hour.hint=如果您不想在作业失败时自动重启，请留空。
job.info.open.job.files=在 GCS 中显示作业文件夹
job.info.properties=属性
job.info.query.file=查询\:
job.info.query.file.value=查询文件\:
job.info.query.text.value=查询文本\:
job.info.query.type=查询源\:
job.info.single.file.hint=可以是带有 gs\:// 前缀的 GCS 文件、集群上带有 hdfs\:// 前缀的 HDFS 文件或集群上带有 file\:// 前缀的本地文件
job.info.spark.additional.py.files=附加 Python 文件\:
job.info.spark.additional.py.files.title=选择附加 Py 文件
job.info.spark.additional.r.files=附加 R 文件\:
job.info.spark.additional.r.files.title=选择附加 R 文件
job.info.spark.archives=归档\:
job.info.spark.archives.hint=归档文件已在 Spark 工作目录中提取。可以是带有 gs\:// 前缀的 GCS 文件、集群上带有 hdfs\:// 前缀的 HDFS 文件或集群上带有 file\:// 前缀的本地文件。支持的文件类型包括\: .jar、.tar、.tar.gz、.tgz、.zip。
job.info.spark.archives.title=选择归档
job.info.spark.args=实参\:
job.info.spark.files=文件\:
job.info.spark.jars=Jar\:
job.info.spark.jars.hint=Jar 文件包含在 CLASSPATH 中。可以是带有 gs\:// 前缀的 GCS 文件、集群上带有 hdfs\:// 前缀的 HDFS 文件或集群上带有 file\:// 前缀的本地文件。
job.info.spark.jars.title=JAR
job.info.spark.main.class=主类\:
job.info.spark.main.py.file.title=选择主 Py 文件
job.info.spark.main.pyfile=主 Python 文件\:
job.info.spark.main.r.file=主 R 文件\:
job.info.spark.main.r.file.title=选择主 R 文件
job.info.start.date=开始日期\:
job.info.status=状态\:
job.info.status.details=状态详细信息\:
job.info.type=作业类型\:
job.label.block.title=标签
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=属性
job.pyspark.title=PySpark
job.query.file.dialog.title=选择查询文件\:
job.query.file.label=查询文件\:
job.query.source.file=文件
job.query.source.text=文本
job.query.source.type=查询类型\:
job.query.text.hint=要执行的查询
job.query.text.label=查询文本\:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=有效
job.state.canceled=已取消
job.state.done=完成
job.state.failed=已失败
job.validation.file.archive={0} 必须为归档类型 .jar、.tar、.tar.gz、.tgz、.zip。
job.validation.file.fs={0} 必须为带有 gs\://、hdfs\:// 或 file\:// 前缀的文件
metainfo.cluster.id=ID\:
metainfo.cluster.name=名称\:
metainfo.cluster.status=状态\:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=不支持检测 {0} 的主类。
settings.application.class.name.error.msg=请先选择 jar 文件
task.init.ssh.perform.cli.command=正在执行 GCloud CLI 命令…
task.init.ssh.title=Dataproc CLI 执行
