alibaba.bucket.create.dialog.hierarchical.field=分层命名空间
alibaba.bucket.create.dialog.versioning=启用版本控制
alibaba.custom.endpoint.text=自定义
alibaba.region.oss-ap-northeast-1=日本(东京)
alibaba.region.oss-ap-northeast-2=韩国(首尔)
alibaba.region.oss-ap-south-1=印度(孟买)
alibaba.region.oss-ap-southeast-1=澳大利亚(悉尼) 1
alibaba.region.oss-ap-southeast-2=澳大利亚(悉尼) 2
alibaba.region.oss-ap-southeast-3=马来西亚(吉隆坡)
alibaba.region.oss-ap-southeast-5=印度尼西亚(雅加达)
alibaba.region.oss-ap-southeast-6=菲律宾(马尼拉)
alibaba.region.oss-ap-southeast-7=泰国(曼谷)
alibaba.region.oss-cn-beijing=中国(北京)
alibaba.region.oss-cn-chengdu=中国(成都)
alibaba.region.oss-cn-guangzhou=中国(广州)
alibaba.region.oss-cn-hangzhou=中国(杭州)
alibaba.region.oss-cn-heyuan=中国(河源)
alibaba.region.oss-cn-hongkong=中国(香港)
alibaba.region.oss-cn-huhehaote=中国(呼和浩特)
alibaba.region.oss-cn-nanjing=中国(南京-本地区域)
alibaba.region.oss-cn-qingdao=中国(青岛)
alibaba.region.oss-cn-shanghai=中国(上海)
alibaba.region.oss-cn-shenzhen=中国(深圳)
alibaba.region.oss-cn-wulanchabu=中国(乌兰察布)
alibaba.region.oss-cn-zhangjiakou=中国(张家口)
alibaba.region.oss-eu-central-1=德国(法兰克福)
alibaba.region.oss-eu-west-1=英国(伦敦)
alibaba.region.oss-me-east-1=阿联酋(迪拜)
alibaba.region.oss-us-east-1=美国(弗吉尼亚州)
alibaba.region.oss-us-west-1=美国(硅谷)
alibaba.settings.credentials.file=Alibaba 凭据文件
alibaba.task.delete.bucket.text=正在删除存储桶 {0}
alibaba.task.delete.directory.text=正在删除目录 {0}
alibaba.task.delete.directory.text2=已删除 {0} 个对象
alibaba.task.delete.file.text=正在删除文件 {0}
azure.column.name.access.tier=访问层级
azure.rename.text2.indicator.deleting={0}\: 正在删除 {1}
bucket.name.is.empty.for.path=路径“{0}”的存储桶名称为空
cannot.find.linode.region=找不到 {0} 的区域
cannot.open.read.stream.null.blob=无法打开 null blob {0} 的读取流
client.is.not.inited=客户端未初始化
cloudflare.config.account.id.label=帐户 ID\:
cloudflare.config.account.id.text=帐户 ID
cloudflare.config.custom.endpoint.label=端点\:
cloudflare.config.selection.endpoint=自定义端点
cloudflare.region.apac=亚太地区
cloudflare.region.auto=自动
cloudflare.region.eeur=东欧
cloudflare.region.enam=北美东部
cloudflare.region.oc=大洋洲
cloudflare.region.weur=西欧
cloudflare.region.wnam=北美西部
connection.error.fs.and.user.not.found=找不到 URI {0} 和用户 {1} 的文件系统
connection.error.hadoop.home.is.not.defined.full=HADOOP_HOME 未定义。在 Windows 上，您应该定义 HADOOP_HOME 环境变量或 Java 属性 hadoop.home.dir。请参阅 <a href\=\\"https\://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\\">Hadoop Wiki</a>，了解更多详细信息。
connection.error.hadoop.no.native.drivers.full=无法在 HADOOP_HOME 中找到原生驱动程序。请参阅 <a href\=\\"https\://cwiki.apache.org/confluence/display/HADOOP2/WindowsProblems\\">Hadoop Wiki</a>，了解更多详细信息。
connection.error.root.path.must.be.non.empty=根路径必须为非空
controller.cluster.instances.error=更新集群实例错误
controller.cluster.steps.error=集群步骤更新错误
copy.failed=从 {0} 复制到 {1} 失败。
custom.bucket.text.empty=bucket/folder,bucket2/folder/subfolder2,…
custom.bucket.text.hint=使用“,”分隔符指定源根列表 (bucket1/folder1/folder2,bucket2/folder)
do.region.ams3=荷兰阿姆斯特丹
do.region.blr1=德国柏林
do.region.fra1=德国法兰克福
do.region.nyc3=美国纽约市
do.region.sfo=美国旧金山
do.region.sgp1=新加坡
do.region.syd1=澳大利亚悉尼
emr.cluster.filter=按状态筛选
emr.cluster.filter.limit=限制
emr.cluster.info.details=显示为 JSON
emr.cluster.terminate.cluster.message=是否要终止集群 {0}?
emr.cluster.terminate.cluster.title=集群正在终止
emr.connection.creation=EMR 创建连接
emr.connection.warning.no.clusters=已连接，找不到集群
emr.connection.warning.no.clusters.desc=已建立连接，但找不到所选区域的集群。请检查区域是否正确。
emr.connection.warning.no.clusters.desc.window=在“{0}”区域找不到集群。请检查区域。
emr.dialog.title.select.key.info.cancel=取消
emr.dialog.title.select.key.info.msg=连接需要创建 SSH 隧道。要设置，请选择集群的 SSH 密钥文件。
emr.dialog.title.select.key.info.ok=选择 SSH 密钥
emr.dialog.title.select.key.info.title=需要 SSH 密钥
emr.dialog.title.select.key.ssh.file=选择 SSH 密钥文件
emr.error=AWS EMR 异常
emr.error.remove.cluster=移除集群时出错
emr.error.start.cluster=启动集群时出错
emr.error.stop.cluster=停止集群错误
emr.filter.text=筛选器\:
emr.is.not.inited=EMR 客户端未初始化
emr.key.storage.dialog.title=EMR SSH 密钥库
emr.keys.settings.column.key.name=键名
emr.keys.settings.column.key.path=路径
emr.keys.settings.label=SSH 密钥\:
emr.keys.settings.table.empty=未提供 SSH 密钥
emr.label.choose.key.file.for.aws.pair=为 AWS {0} 对选择密钥文件
emr.remove.linked.connections.action=移除连接
emr.remove.linked.connections.desc=是否要删除为 EMR 创建的连接?
emr.remove.linked.connections.title=EMR 连接
emr.spark.submit=EMR Spark-submit
emr.spark.submit.editor.args=实参\:
emr.spark.submit.editor.jar.loc=JAR 位置\:
emr.spark.submit.editor.name=名称\:
emr.step.details=显示步骤详细信息
emr.step.mapper.choose=选择 Mapper
emr.step.reducer.choose=选择 Reducer
emr.step.s3.input.choose=选择 S3 输入
emr.step.s3.output.choose=选择 S3 输出
emr.step.script.choose=选择 S3 脚本位置
emr.toolwindow.title=AWS EMR
error.krb5.conf=无法通过 Kerberos 授权。尝试向 krb5.conf 添加 "allow_weak_crypto \= true"
error.object.summary.is.not.found=没有 {0} 的对象摘要
file.info.access.blob.type=Blob 类型
file.info.access.content.type=内容类型
file.info.access.tier=访问层级
file.info.access.tier.modified=访问层级上次修改时间
gcs.buckets.source=存储桶源\:
gcs.connection.browse.title=选择凭据 JSON
gcs.connection.error.bucket.validation1=存储桶名称必须包含 3-63 个字符。包含点的名称最多可包含 222 个字符，但每个以点分隔的组件不得超过 63 个字符。
gcs.connection.error.bucket.validation2=名称只能包含小写字母、数字、破折号(-)、下划线(_)和点(.)。
gcs.connection.error.bucket.validation3=存储桶名称必须以数字或字母开头和结尾。
gcs.connection.error.bucket.validation4=存储桶名称不能表示为用点分隔的十进制形式的 IP 地址(例如 192.168.5.4)。
gcs.connection.error.bucket.validation5=存储桶名称不能以“goog”前缀开头。
gcs.connection.error.bucket.validation6=存储桶名称不能包含“google”或相近的错误拼写，例如“g00gle”。
gcs.connection.error.cred.file.not.selected=必须为帐号选择凭据文件
gcs.connection.error.file.not.exists=文件不存在
gcs.json.location.emptyText=云存储 JSON 位置
gcs.multibucket.update.text=Google Cloud Storage 支持多存储桶\! 您可以在连接设置中配置它们。
gcs.multibucket.update.title=BigDataTools 的新 GCS 功能
gcs.progress.details.deleting=正在删除 {0}
gcs.project.id=项目 ID\:
gcs.project.id.emptyText=可选的覆盖项目 ID
gcs.project.id.hint=显示特殊项目 ID 的存储桶
gcs.public.hint=为公共存储桶留空
group.name.alibaba=Alibaba OSS
group.name.azure=Azure
group.name.cloudflare=Cloudflare R2
group.name.dospaces=DigitalOcean Spaces
group.name.emr=AWS EMR
group.name.gcs=Google Cloud Storage
group.name.hdfs.java=HDFS
group.name.linode=Linode
group.name.minio=MinIO
group.name.s3=AWS S3
group.name.yandex=Yandex 对象存储
group.names.hdfs.data=HDFS 问题
hdfs.column.name.access.time=访问时间
hdfs.column.name.block.size=块大小
hdfs.column.name.group=组
hdfs.column.name.is.encrypted=已加密
hdfs.column.name.is.isErasureCoded=已使用纠删码
hdfs.column.name.is.isSnapshotEnabled=快照
hdfs.column.name.owner=所有者
hdfs.column.name.permission=权限
hdfs.column.name.replications=副本
hdfs.config.path.does.not.exist=指定的目录不存在
hdfs.config.path.no.xmls.found=指定的目录不包含任何 XML 文件
hdfs.config.path.not.empty=配置路径不应为空
hdfs.config.path.should.be.directory=配置路径应该指向一个目录
hdfs.config.path.title=Java API 配置路径
hdfs.field.root.path=根路径
hdfs.file.info.label.accessTime=访问时间\:
hdfs.file.info.label.block.size=块大小\:
hdfs.file.info.label.group=组\:
hdfs.file.info.label.isEncrypted=已加密\:
hdfs.file.info.label.isErasureCoded=已使用纠删码\:
hdfs.file.info.label.isSnapshotEnabled=已启用快照\:
hdfs.file.info.label.modificationTime=修改时间\:
hdfs.file.info.label.owner=所有者\:
hdfs.file.info.label.permission=权限\:
hdfs.file.info.label.replication=副本\:
hdfs.file.info.label.size=大小\:
hdfs.is.not.inited=Hdfs 连接未初始化
hdfs.java.config.source=配置源\:
hdfs.java.driver.home.path=驱动程序主路径\:
hdfs.no.xmls.in.directory=配置根中没有 XML 文件
hdfs.property.source.directory=配置文件夹
hdfs.property.source.explicit=自定义
hdfs.root.folder.does.not.exist=根文件夹 {0} 不存在
hdfs.ssh.tunnel.ssh.operation.not.supported=不支持通过 SSH 隧道进行操作。
kerberos.type.credentials=密码
kerberos.type.disabled=已禁用
kerberos.type.keytab=键表
kerberos.type.subject=JAAS 配置(专家)
linode.region.ap-south=新加坡
linode.region.br-gru-1=巴西圣保罗
linode.region.eu-central=德国法兰克福
linode.region.fr-par-1=法国巴黎
linode.region.id-cgk-1=印度尼西亚雅加达
linode.region.in-maa-1=印度钦奈
linode.region.it-mil-1=意大利米兰
linode.region.jp-osa-1=日本大阪
linode.region.nl-ams-1=荷兰阿姆斯特丹
linode.region.se-sto-1=瑞典斯德哥尔摩
linode.region.us-east=美国新泽西州纽瓦克
linode.region.us-iad-1=美国华盛顿特区
linode.region.us-lax-1=美国加利福尼亚州洛杉矶
linode.region.us-mia-1=美国佛罗里达州迈阿密
linode.region.us-ord-1=美国伊利诺伊州芝加哥
linode.region.us-sea-1=美国华盛顿州西雅图
linode.region.us-southeast=美国佐治亚州亚特兰大
metainfo.headers.empty=无自定义标头
metainfo.headers.key=键
metainfo.headers.value=值
metainfo.section.custom.headers=标头
minio.region.text.empty=使用默认值
move.failed=从 {0} 移动到 {1} 失败。
notification.group.orc.files=ORC 文件
oss.file.info.label.hns.status=分层命名空间\:
oss.file.info.label.hns.status.disabled=已禁用
oss.file.info.label.type=Content-Type\:
rfs.create.bucket.message=创建存储桶
s3.bucket.text.empty=所有存储桶均可见
s3.bucket.text.hint=如果此字段为空，则所有存储桶都将可见<br>输入存储桶名称并选择筛选器类型“匹配”以处理单个存储桶<br>使用“,”分隔存储桶(bucket1, bucket2)
s3.column.name.etag=ETag
s3.column.name.metadata=元数据
s3.column.name.storage.class=存储类
s3.connection.error.ssh.without.endpoint=要使用 SSH 隧道，请为驱动程序指定一个端点
s3.empty.directories.not.allowed=不允许创建空目录
s3.multibucket.open.settings=打开设置
s3.multibucket.update.text=S3 兼容存储支持多存储桶。您可以在连接设置中配置它们。
s3.multibucket.update.title=BigDataTools 的新 S3 功能
settings.alibaba.region=区域\:
settings.azure.connection.string=连接字符串\:
settings.azure.container=容器\:
settings.azure.endpoint=端点\:
settings.azure.password=密码\:
settings.azure.sas.token=SAS 令牌\:
settings.azure.user.key=密钥\:
settings.azure.username=用户名\:
settings.bucket.filter=存储桶筛选器\:
settings.bucket.filter.type=筛选器类型\:
settings.buckets.custom.list=自定义根
settings.buckets.hint=<html><b>帐户中的所有存储桶</b> - 执行某种 <it>list buckets</it> 请求。允许筛选结果存储桶列表。<br><br><b>自定义根</b> - 直接请求所选根，不仅允许指定存储桶，还允许指定目录的完整路径。</html>
settings.buckets.user.list=帐户中的所有存储桶
settings.config.from.folder=解析的配置\:
settings.config.path=配置路径\:
settings.custom.roots=根\:
settings.generate.kerberos=Kerberos
settings.hdfs.auth.type=身份验证\:
settings.hdfs.kerberos.type=身份验证方法\:
settings.hdfs.kinit=使用 kinit 缓存
settings.hdfs.url=集群 URI\:
settings.hdfs.username=Hadoop 用户名\:
settings.hdfs.username.hint=登录服务器的用户名。如果未指定，则使用 <i>HAD00P_USER_NAME</i> 环境变量。如果未定义此变量，则使用 <i>user.name</i> 属性。如果启用了 Kerberos，它将重写这三个值。
settings.kerberos.auth=身份验证\:
settings.kerberos.auth.kerberos=Kerberos
settings.kerberos.auth.none=无
settings.minio.endpoint=端点\:
settings.properties=高级配置\:
settings.s3.bucket.filter.by.region=仅限所选区域中的存储桶
settings.s3.custom.endpoint=端点\:
settings.s3.custom.region=区域\:
settings.s3.custom.region.hint=需要时使用
settings.s3.region=区域\:
settings.s3.region.group=AWS S3
settings.s3.selection.endpoint=与 S3 兼容的存储
settings.undefined.path=<未初始化>
settings.validation.kerberos.keytab.error=必须指定键表和主体
settings.validation.kerberos.password.error=必须指定主体和密码
ssh.additional.info=SSH 隧道<b>仅适用于名称节点的操作</b>\: 列出文件，获取元信息。<br><br>
ssh.additional.label=(仅限 NameNode 操作)
wrong.region=找不到区域“{0}”
